{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# Load known faces\n",
    "def load_known_faces():\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "    image_folder = \"sample_images\"\n",
    "\n",
    "    if not os.path.exists(image_folder):\n",
    "        os.makedirs(image_folder)\n",
    "\n",
    "    for file in os.listdir(image_folder):\n",
    "        if file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            image_path = os.path.join(image_folder, file)\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "            if encodings:\n",
    "                known_face_encodings.append(encodings[0])\n",
    "                known_face_names.append(os.path.splitext(file)[0])  # Save filename without extension\n",
    "    return known_face_encodings, known_face_names\n",
    "\n",
    "# Find correct file format for a given name\n",
    "def find_image_file(directory, name):\n",
    "    for file in os.listdir(directory):\n",
    "        if file.lower().startswith(name.lower()) and file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            return os.path.join(directory, file)\n",
    "    return None\n",
    "\n",
    "#**********************************************************************************************************************************\n",
    "#                                     *** Basic Image Face recognition  with dataset ***                                          |\n",
    "#**********************************************************************************************************************************\n",
    "\n",
    "def recognize_faces_from_image(known_face_encodings, known_face_names, test_image_path):\n",
    "    if not os.path.exists(test_image_path):\n",
    "        print(\"Test image not found!\")\n",
    "        return\n",
    "\n",
    "    # Load the test image\n",
    "    test_image = face_recognition.load_image_file(test_image_path)\n",
    "    test_rgb_image = cv2.cvtColor(test_image, cv2.COLOR_RGB2BGR)  # Convert to OpenCV format\n",
    "\n",
    "    # Detect faces and encode\n",
    "    test_encodings = face_recognition.face_encodings(test_image)\n",
    "    if not test_encodings:\n",
    "        print(\"No face detected in test image!\")\n",
    "        return\n",
    "\n",
    "    test_encoding = test_encodings[0]  # Take the first face\n",
    "\n",
    "    # Compare with known faces\n",
    "    matches = face_recognition.compare_faces(known_face_encodings, test_encoding)\n",
    "    face_distances = face_recognition.face_distance(known_face_encodings, test_encoding)\n",
    "\n",
    "    if True in matches:\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        matched_name = known_face_names[best_match_index]\n",
    "        \n",
    "        # Find correct image file\n",
    "        matched_image_path = find_image_file(\"sample_images\", matched_name)\n",
    "\n",
    "        if matched_image_path:\n",
    "            matched_image = cv2.imread(matched_image_path)\n",
    "            matched_image = cv2.resize(matched_image, (test_rgb_image.shape[1], test_rgb_image.shape[0]))       \n",
    "            # Convert test image to PIL format\n",
    "            test_pil = Image.fromarray(test_rgb_image)\n",
    "            matched_pil = Image.fromarray(matched_image)\n",
    "\n",
    "            # Display images side by side\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            axes[0].imshow(test_pil)\n",
    "            axes[0].set_title(\"Test Image\")\n",
    "            axes[0].axis(\"off\")\n",
    "\n",
    "            axes[1].imshow(matched_pil)\n",
    "            axes[1].set_title(f\"Matched: {matched_name}\")\n",
    "            axes[1].axis(\"off\")\n",
    "\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Matched with {matched_name}, but image file not found.\")\n",
    "    else:\n",
    "        print(\"No match found in dataset!\")\n",
    "\n",
    "#**********************************************************************************************************************************\n",
    "#                                          ðŸ“¹ FACE RECOGNITION -from a live camera feed                                           |\n",
    "#**********************************************************************************************************************************\n",
    "def live_face_recognition(known_face_encodings, known_face_names, camera_index=0, in_jupyter=False):\n",
    "    video_capture = cv2.VideoCapture(camera_index)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        rgb_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            if True in matches:\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if face_distances[best_match_index] < 0.5:\n",
    "                    name = known_face_names[best_match_index]\n",
    "\n",
    "            # Scale back face location\n",
    "            top, right, bottom, left = top * 2, right * 2, bottom * 2, left * 2\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame, (left, top - 25), (right, top), (0, 0, 0), cv2.FILLED)\n",
    "            cv2.putText(frame, name, (left + 5, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "        if in_jupyter:\n",
    "            # Convert to PIL Image for Jupyter display\n",
    "            img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            clear_output(wait=True)  # Clear previous output\n",
    "            display(img_pil)  # Show updated frame\n",
    "        else:\n",
    "            # Show in normal OpenCV window\n",
    "            cv2.imshow('Live Face Recognition', frame)\n",
    "\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#**********************************************************************************************************************************\n",
    "#                                      ðŸ”’ Face Lock System                                                                        |\n",
    "#**********************************************************************************************************************************\n",
    "def face_lock_system(known_face_encodings, known_face_names, camera_index=0, in_jupyter=False):\n",
    "    video_capture = cv2.VideoCapture(camera_index)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        rgb_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        access_granted = False\n",
    "        detected_name = \"Unknown\"\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "            if True in matches:\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if face_distances[best_match_index] < 0.5:  # Accept matches below threshold\n",
    "                    detected_name = known_face_names[best_match_index]\n",
    "                    access_granted = True\n",
    "\n",
    "            # Scale face location back\n",
    "            top, right, bottom, left = top * 2, right * 2, bottom * 2, left * 2\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)  # Bounding box\n",
    "\n",
    "        if access_granted:\n",
    "            message = f\"âœ… Access Granted: {detected_name}\"\n",
    "        else:\n",
    "            message = \"âŒ Access Denied!\"\n",
    "\n",
    "        if in_jupyter:\n",
    "            clear_output(wait=True)  # Clear previous output\n",
    "            # Convert to PIL Image for Jupyter display\n",
    "            img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            display(img_pil, message)  # Show updated frame\n",
    "        else:\n",
    "            # Show in normal OpenCV window\n",
    "            cv2.imshow('Live Face Recognition', frame)\n",
    "            print(message)\n",
    "\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "            \n",
    "    \n",
    "    \n",
    "#**********************************************************************************************************************************\n",
    "#                                              RUN THE SYSTEM -by Calling Function                                                   |\n",
    "#**********************************************************************************************************************************\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    known_face_encodings, known_face_names = load_known_faces()\n",
    "\n",
    "# Note : Uncomment to run Image-to-Image recognition\n",
    "    # recognize_faces_from_image(known_face_encodings, known_face_names, \"sample_images/Leonardo DiCaprio.jpg\")\n",
    "    \n",
    "# Note : Uncomment to run Default Face recognition with live cam Feed (TRUE/FALSE for running In-Jupyter OR External Window )\n",
    "    \n",
    "    # live_face_recognition(known_face_encodings, known_face_names, in_jupyter=False)\n",
    "    # live_face_recognition(known_face_encodings, known_face_names, in_jupyter=True)\n",
    "\n",
    "# Note : Uncomment to run FACE LOCK SIMULATION with Authorised Users in dataset (TRUE/FALSE for running In-Jupyter OR External Window ) \n",
    "    # face_lock_system(known_face_encodings, known_face_names, in_jupyter=False)\n",
    "    face_lock_system(known_face_encodings, known_face_names, in_jupyter=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
